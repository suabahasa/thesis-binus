{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import MBartForConditionalGeneration\n",
    "from torch import optim\n",
    "\n",
    "import nltk\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import pipeline\n",
    "\n",
    "from repo.indobenchmark.toolkit.tokenization_indonlg import IndoNLGTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "# check if cuda or mps available, if available, use one of them, otherwise use cpu\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('using cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"1\" # This is tracked as pytorch issue #98222\n",
    "    print('using mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jakarta, CNN Indonesia - - Dokter Ryan Thamrin...</td>\n",
       "      <td>None</td>\n",
       "      <td>Dokter Lula Kamal yang merupakan selebriti sek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selfie ialah salah satu tema terpanas di kalan...</td>\n",
       "      <td>None</td>\n",
       "      <td>Asus memperkenalkan   ZenFone generasi keempat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jakarta, CNN Indonesia - - Dinas Pariwisata Pr...</td>\n",
       "      <td>None</td>\n",
       "      <td>Dinas Pariwisata Provinsi Bengkulu kembali men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merdeka.com - Indonesia Corruption Watch (ICW)...</td>\n",
       "      <td>None</td>\n",
       "      <td>Indonesia Corruption Watch (ICW) meminta Komis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Merdeka.com - Presiden Joko Widodo (Jokowi) me...</td>\n",
       "      <td>None</td>\n",
       "      <td>Jokowi memimpin upacara penurunan bendera. Usa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document    id  \\\n",
       "0  Jakarta, CNN Indonesia - - Dokter Ryan Thamrin...  None   \n",
       "1  Selfie ialah salah satu tema terpanas di kalan...  None   \n",
       "2  Jakarta, CNN Indonesia - - Dinas Pariwisata Pr...  None   \n",
       "3  Merdeka.com - Indonesia Corruption Watch (ICW)...  None   \n",
       "4  Merdeka.com - Presiden Joko Widodo (Jokowi) me...  None   \n",
       "\n",
       "                                             summary  \n",
       "0  Dokter Lula Kamal yang merupakan selebriti sek...  \n",
       "1  Asus memperkenalkan   ZenFone generasi keempat...  \n",
       "2  Dinas Pariwisata Provinsi Bengkulu kembali men...  \n",
       "3  Indonesia Corruption Watch (ICW) meminta Komis...  \n",
       "4  Jokowi memimpin upacara penurunan bendera. Usa...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset('./repo/SEACrowd/indosum/indosum.py')\n",
    "# ds = load_dataset('maryantocinn/indosum')\n",
    "\n",
    "# data_train = ds['train']\n",
    "# data_val = ds['validation']\n",
    "# data_test = ds['test']\n",
    "\n",
    "# show first 5 data from the dataset in pandas like table\n",
    "pd.DataFrame(ds['train'][:5]).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length:  14262\n",
      "Validation dataset length:  750\n",
      "Test dataset length:  3762\n"
     ]
    }
   ],
   "source": [
    "# check the length of the dataset\n",
    "print(\"Train dataset length: \", len(ds['train']))\n",
    "print(\"Validation dataset length: \", len(ds['validation']))\n",
    "print(\"Test dataset length: \", len(ds['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bart_model = AutoModelForSeq2SeqLM.from_pretrained('indobenchmark/indobart-v2')\n",
    "\n",
    "bart_model = MBartForConditionalGeneration.from_pretrained('indobenchmark/indobart-v2')\n",
    "indonlg_tokenizer = IndoNLGTokenizer.from_pretrained('indobenchmark/indobart-v2')\n",
    "\n",
    "model = bart_model\n",
    "tokenizer = indonlg_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5349' max='5349' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5349/5349 20:17, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>0.521733</td>\n",
       "      <td>0.337352</td>\n",
       "      <td>0.295579</td>\n",
       "      <td>0.328877</td>\n",
       "      <td>0.333751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.423600</td>\n",
       "      <td>0.503219</td>\n",
       "      <td>0.340289</td>\n",
       "      <td>0.298195</td>\n",
       "      <td>0.332033</td>\n",
       "      <td>0.336670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.334100</td>\n",
       "      <td>0.509233</td>\n",
       "      <td>0.340637</td>\n",
       "      <td>0.298790</td>\n",
       "      <td>0.332058</td>\n",
       "      <td>0.336892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/thesis-binus/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "/home/paperspace/thesis-binus/.venv/lib/python3.9/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/paperspace/thesis-binus/.venv/lib/python3.9/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/home/paperspace/thesis-binus/.venv/lib/python3.9/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5349, training_loss=0.45868174235026044, metrics={'train_runtime': 1217.706, 'train_samples_per_second': 35.137, 'train_steps_per_second': 4.393, 'total_flos': 1.6099778535284736e+16, 'train_loss': 0.45868174235026044, 'epoch': 3.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare and tokenize dataset\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(examples[\"document\"], max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Setup evaluation\n",
    "nltk.download(\"punkt_tab\", quiet=True)\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # decode preds and labels\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    return result\n",
    "\n",
    "tokenized_ds = ds.map(preprocess_function, batched=True)\n",
    "\n",
    "# Load pretrained model and evaluate model after each epoch\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results/00-indobart\",\n",
    "    # overwrite_output_dir=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=3.75e-5, # hf example: 2e-5\n",
    "    per_device_train_batch_size=8, # hf example: 16\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3, # hf example: 2\n",
    "    fp16=True, # not supported on apple sillicon chip (mps)\n",
    "    predict_with_generate=True,\n",
    "    # save_strategy=\"no\",\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    processing_class=tokenizer, # FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`.\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test Data and evaluate the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/thesis-binus/.venv/lib/python3.9/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE scores on the test set: {'rouge1': np.float64(0.33772576546706445), 'rouge2': np.float64(0.2954139183415241), 'rougeL': np.float64(0.32883016702331247), 'rougeLsum': np.float64(0.33381442413528517)}\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "test_predictions = trainer.predict(tokenized_ds['test'])\n",
    "\n",
    "# Get the predictions and labels from the result\n",
    "preds = test_predictions.predictions\n",
    "labels = test_predictions.label_ids\n",
    "\n",
    "# Evaluate using the compute_metrics function\n",
    "rouge_scores = compute_metrics((preds, labels))\n",
    "\n",
    "# Print the ROUGE scores\n",
    "print(\"ROUGE scores on the test set:\", rouge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5360028147697449,\n",
       " 'eval_rouge1': 0.33772576546706445,\n",
       " 'eval_rouge2': 0.2954139183415241,\n",
       " 'eval_rougeL': 0.32883016702331247,\n",
       " 'eval_rougeLsum': 0.33381442413528517,\n",
       " 'eval_runtime': 342.2997,\n",
       " 'eval_samples_per_second': 10.99,\n",
       " 'eval_steps_per_second': 2.749,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# get device\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "# create table to show the result: document, summary, generated_summary\n",
    "df = pd.DataFrame(columns=['document', 'summary', 'generated_summary'])\n",
    "for i in range(5):\n",
    "    document = ds['test'][i]['document']\n",
    "    summary = ds['test'][i]['summary']\n",
    "    generated_summary = summarizer(document, min_length=5, max_length=80)\n",
    "    df = pd.concat([df, pd.DataFrame([[document, summary, generated_summary[0]['summary_text']]], columns=['document', 'summary', 'generated_summary'])], ignore_index=True)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# save the result to a csv file\n",
    "# Specify the directory and file path\n",
    "directory = 'benc_result/00-indobart/'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_json(f'{directory}/summarization_result.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
