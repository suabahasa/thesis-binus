{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from src.datasets import IndoSum\n",
    "from src.common import get_device\n",
    "from src.indobart.base import get_model, get_tokenizer\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import evaluate\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "from accelerate import Accelerator\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"all\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'id', 'summary'],\n",
       "        num_rows: 14262\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'id', 'summary'],\n",
       "        num_rows: 3762\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'id', 'summary'],\n",
       "        num_rows: 750\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indosum = IndoSum()\n",
    "indosum.ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jakarta, CNN Indonesia - - Dokter Ryan Thamrin...</td>\n",
       "      <td>1501893029-lula-kamal-dokter-ryan-thamrin-saki...</td>\n",
       "      <td>Dokter Lula Kamal yang merupakan selebriti sek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selfie ialah salah satu tema terpanas di kalan...</td>\n",
       "      <td>1509072914-dua-smartphone-zenfone-baru-tawarka...</td>\n",
       "      <td>Asus memperkenalkan   ZenFone generasi keempat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jakarta, CNN Indonesia - - Dinas Pariwisata Pr...</td>\n",
       "      <td>1510613677-songsong-visit-2020-bengkulu-perkua...</td>\n",
       "      <td>Dinas Pariwisata Provinsi Bengkulu kembali men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merdeka.com - Indonesia Corruption Watch (ICW)...</td>\n",
       "      <td>1502706803-icw-ada-kejanggalan-atas-tewasnya-s...</td>\n",
       "      <td>Indonesia Corruption Watch (ICW) meminta Komis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Merdeka.com - Presiden Joko Widodo (Jokowi) me...</td>\n",
       "      <td>1503039338-pembagian-sepeda-usai-upacara-penur...</td>\n",
       "      <td>Jokowi memimpin upacara penurunan bendera. Usa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  Jakarta, CNN Indonesia - - Dokter Ryan Thamrin...   \n",
       "1  Selfie ialah salah satu tema terpanas di kalan...   \n",
       "2  Jakarta, CNN Indonesia - - Dinas Pariwisata Pr...   \n",
       "3  Merdeka.com - Indonesia Corruption Watch (ICW)...   \n",
       "4  Merdeka.com - Presiden Joko Widodo (Jokowi) me...   \n",
       "\n",
       "                                                  id  \\\n",
       "0  1501893029-lula-kamal-dokter-ryan-thamrin-saki...   \n",
       "1  1509072914-dua-smartphone-zenfone-baru-tawarka...   \n",
       "2  1510613677-songsong-visit-2020-bengkulu-perkua...   \n",
       "3  1502706803-icw-ada-kejanggalan-atas-tewasnya-s...   \n",
       "4  1503039338-pembagian-sepeda-usai-upacara-penur...   \n",
       "\n",
       "                                             summary  \n",
       "0  Dokter Lula Kamal yang merupakan selebriti sek...  \n",
       "1  Asus memperkenalkan   ZenFone generasi keempat...  \n",
       "2  Dinas Pariwisata Provinsi Bengkulu kembali men...  \n",
       "3  Indonesia Corruption Watch (ICW) meminta Komis...  \n",
       "4  Jokowi memimpin upacara penurunan bendera. Usa...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indosum.to_pd(\"train\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(\"LazarusNLP/all-indobert-base-v4\")\n",
    "\n",
    "stop_words = (\n",
    "    stopwords.words(\"english\")\n",
    "    + stopwords.words(\"indonesian\")\n",
    "    + StopWordRemoverFactory().get_stop_words()\n",
    ")\n",
    "vectorizer_model = CountVectorizer(stop_words=stop_words, token_pattern=\"[^\\W\\d_]+\")\n",
    "\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    nr_topics=10,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 19:47:19,384 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b73ae6a69914a9badea5aa28c811beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/446 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-12 19:48:09,220 - BERTopic - Embedding - Completed ✓\n",
      "2024-11-12 19:48:09,221 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-11-12 19:48:49,385 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-11-12 19:48:49,388 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-11-12 19:48:50,145 - BERTopic - Cluster - Completed ✓\n",
      "2024-11-12 19:48:50,148 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-11-12 19:48:56,406 - BERTopic - Representation - Completed ✓\n",
      "2024-11-12 19:48:56,416 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2024-11-12 19:49:01,762 - BERTopic - Topic reduction - Reduced number of topics from 203 to 10\n"
     ]
    }
   ],
   "source": [
    "topics, probs = topic_model.fit_transform(indosum.ds[\"train\"][\"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>6031</td>\n",
       "      <td>-1_indonesia_jakarta_orang_pemain</td>\n",
       "      <td>[indonesia, jakarta, orang, pemain, salah, neg...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Indonesia mencatat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1966</td>\n",
       "      <td>0_gol_pemain_laga_menit</td>\n",
       "      <td>[gol, pemain, laga, menit, tim, pertandingan, ...</td>\n",
       "      <td>[JUARA.net - Real Madrid hanya butuh tambahan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1954</td>\n",
       "      <td>1_jakarta_kpk_partai_ketua</td>\n",
       "      <td>[jakarta, kpk, partai, ketua, indonesia, jalan...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Komisi Pemberantas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1169</td>\n",
       "      <td>2_pebalap_startup_rossi_teknologi</td>\n",
       "      <td>[pebalap, startup, rossi, teknologi, berita, i...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Pebalap Movistar Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1092</td>\n",
       "      <td>3_film_lagu_album_konser</td>\n",
       "      <td>[film, lagu, album, konser, jakarta, orang, in...</td>\n",
       "      <td>[Sulit memang, memilih siapa anggota One Direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>621</td>\n",
       "      <td>4_trump_negara_presiden_israel</td>\n",
       "      <td>[trump, negara, presiden, israel, orang, ameri...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Presiden Amerika S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>550</td>\n",
       "      <td>5_indonesia_persen_startup_rp</td>\n",
       "      <td>[indonesia, persen, startup, rp, pemerintah, l...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Menteri Energi dan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>443</td>\n",
       "      <td>6_indonesia_kopi_makanan_festival</td>\n",
       "      <td>[indonesia, kopi, makanan, festival, wisata, p...</td>\n",
       "      <td>[London (ANTARA News) - Duo desainer Italia Mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>423</td>\n",
       "      <td>7_tubuh_makanan_kanker_penyakit</td>\n",
       "      <td>[tubuh, makanan, kanker, penyakit, orang, pene...</td>\n",
       "      <td>[Selain jantung dan stroke, kanker merupakan p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>8_minyak_barel_mentah_opec</td>\n",
       "      <td>[minyak, barel, mentah, opec, harga, produksi,...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Harga minyak menta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                               Name  \\\n",
       "0     -1   6031  -1_indonesia_jakarta_orang_pemain   \n",
       "1      0   1966            0_gol_pemain_laga_menit   \n",
       "2      1   1954         1_jakarta_kpk_partai_ketua   \n",
       "3      2   1169  2_pebalap_startup_rossi_teknologi   \n",
       "4      3   1092           3_film_lagu_album_konser   \n",
       "5      4    621     4_trump_negara_presiden_israel   \n",
       "6      5    550      5_indonesia_persen_startup_rp   \n",
       "7      6    443  6_indonesia_kopi_makanan_festival   \n",
       "8      7    423    7_tubuh_makanan_kanker_penyakit   \n",
       "9      8     13         8_minyak_barel_mentah_opec   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [indonesia, jakarta, orang, pemain, salah, neg...   \n",
       "1  [gol, pemain, laga, menit, tim, pertandingan, ...   \n",
       "2  [jakarta, kpk, partai, ketua, indonesia, jalan...   \n",
       "3  [pebalap, startup, rossi, teknologi, berita, i...   \n",
       "4  [film, lagu, album, konser, jakarta, orang, in...   \n",
       "5  [trump, negara, presiden, israel, orang, ameri...   \n",
       "6  [indonesia, persen, startup, rp, pemerintah, l...   \n",
       "7  [indonesia, kopi, makanan, festival, wisata, p...   \n",
       "8  [tubuh, makanan, kanker, penyakit, orang, pene...   \n",
       "9  [minyak, barel, mentah, opec, harga, produksi,...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [Jakarta, CNN Indonesia - - Indonesia mencatat...  \n",
       "1  [JUARA.net - Real Madrid hanya butuh tambahan ...  \n",
       "2  [Jakarta, CNN Indonesia - - Komisi Pemberantas...  \n",
       "3  [Jakarta, CNN Indonesia - - Pebalap Movistar Y...  \n",
       "4  [Sulit memang, memilih siapa anggota One Direc...  \n",
       "5  [Jakarta, CNN Indonesia - - Presiden Amerika S...  \n",
       "6  [Jakarta, CNN Indonesia - - Menteri Energi dan...  \n",
       "7  [London (ANTARA News) - Duo desainer Italia Mi...  \n",
       "8  [Selain jantung dan stroke, kanker merupakan p...  \n",
       "9  [Jakarta, CNN Indonesia - - Harga minyak menta...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_info = topic_model.get_topic_info()\n",
    "\n",
    "# save to excel\n",
    "os.makedirs(f\"./results/00-bertopic-indobart\", exist_ok=True)\n",
    "topic_info.to_csv(f\"./results/00-bertopic-indobart/topic_info.csv\")\n",
    "\n",
    "topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jakarta, CNN Indonesia - - Dokter Ryan Thamrin...</td>\n",
       "      <td>1501893029-lula-kamal-dokter-ryan-thamrin-saki...</td>\n",
       "      <td>Dokter Lula Kamal yang merupakan selebriti sek...</td>\n",
       "      <td>Jakarta, CNN Indonesia - - Dokter Ryan Thamrin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_indonesia_jakarta_orang_pemain</td>\n",
       "      <td>[indonesia, jakarta, orang, pemain, salah, neg...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Indonesia mencatat...</td>\n",
       "      <td>indonesia - jakarta - orang - pemain - salah -...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selfie ialah salah satu tema terpanas di kalan...</td>\n",
       "      <td>1509072914-dua-smartphone-zenfone-baru-tawarka...</td>\n",
       "      <td>Asus memperkenalkan   ZenFone generasi keempat...</td>\n",
       "      <td>Selfie ialah salah satu tema terpanas di kalan...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_indonesia_jakarta_orang_pemain</td>\n",
       "      <td>[indonesia, jakarta, orang, pemain, salah, neg...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Indonesia mencatat...</td>\n",
       "      <td>indonesia - jakarta - orang - pemain - salah -...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jakarta, CNN Indonesia - - Dinas Pariwisata Pr...</td>\n",
       "      <td>1510613677-songsong-visit-2020-bengkulu-perkua...</td>\n",
       "      <td>Dinas Pariwisata Provinsi Bengkulu kembali men...</td>\n",
       "      <td>Jakarta, CNN Indonesia - - Dinas Pariwisata Pr...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_indonesia_jakarta_orang_pemain</td>\n",
       "      <td>[indonesia, jakarta, orang, pemain, salah, neg...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Indonesia mencatat...</td>\n",
       "      <td>indonesia - jakarta - orang - pemain - salah -...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merdeka.com - Indonesia Corruption Watch (ICW)...</td>\n",
       "      <td>1502706803-icw-ada-kejanggalan-atas-tewasnya-s...</td>\n",
       "      <td>Indonesia Corruption Watch (ICW) meminta Komis...</td>\n",
       "      <td>Merdeka.com - Indonesia Corruption Watch (ICW)...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_indonesia_jakarta_orang_pemain</td>\n",
       "      <td>[indonesia, jakarta, orang, pemain, salah, neg...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Indonesia mencatat...</td>\n",
       "      <td>indonesia - jakarta - orang - pemain - salah -...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Merdeka.com - Presiden Joko Widodo (Jokowi) me...</td>\n",
       "      <td>1503039338-pembagian-sepeda-usai-upacara-penur...</td>\n",
       "      <td>Jokowi memimpin upacara penurunan bendera. Usa...</td>\n",
       "      <td>Merdeka.com - Presiden Joko Widodo (Jokowi) me...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_jakarta_kpk_partai_ketua</td>\n",
       "      <td>[jakarta, kpk, partai, ketua, indonesia, jalan...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Komisi Pemberantas...</td>\n",
       "      <td>jakarta - kpk - partai - ketua - indonesia - j...</td>\n",
       "      <td>0.918330</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14257</th>\n",
       "      <td>Jakarta, CNN Indonesia - - Amerika Serikat dil...</td>\n",
       "      <td>1497645345-as-kirimkan-peluncur-rudal-ke-suria...</td>\n",
       "      <td>Amerika Serikat dilaporkan telah mengirimkan s...</td>\n",
       "      <td>Jakarta, CNN Indonesia - - Amerika Serikat dil...</td>\n",
       "      <td>4</td>\n",
       "      <td>4_trump_negara_presiden_israel</td>\n",
       "      <td>[trump, negara, presiden, israel, orang, ameri...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Presiden Amerika S...</td>\n",
       "      <td>trump - negara - presiden - israel - orang - a...</td>\n",
       "      <td>0.450864</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14258</th>\n",
       "      <td>Bandung, CNN Indonesia - - Borneo FC berhasil ...</td>\n",
       "      <td>1495406700-borneo-bersyukur-tahan-persib-di-gbla</td>\n",
       "      <td>Borneo FC menahan imbang Persib Bandung pada l...</td>\n",
       "      <td>Bandung, CNN Indonesia - - Borneo FC berhasil ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_indonesia_jakarta_orang_pemain</td>\n",
       "      <td>[indonesia, jakarta, orang, pemain, salah, neg...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Indonesia mencatat...</td>\n",
       "      <td>indonesia - jakarta - orang - pemain - salah -...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14259</th>\n",
       "      <td>JAKARTA (Pos Kota) – Komisi Pemberantasan Koru...</td>\n",
       "      <td>1513941815-mantan-dirjen-perhubungan-laut-sege...</td>\n",
       "      <td>Komisi Pemberantasan Korupsi (KPK) sudah melim...</td>\n",
       "      <td>JAKARTA (Pos Kota) – Komisi Pemberantasan Koru...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_jakarta_kpk_partai_ketua</td>\n",
       "      <td>[jakarta, kpk, partai, ketua, indonesia, jalan...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Komisi Pemberantas...</td>\n",
       "      <td>jakarta - kpk - partai - ketua - indonesia - j...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14260</th>\n",
       "      <td>Merdeka.com - Sebuah kabar gembira datang bagi...</td>\n",
       "      <td>1496440800-rangking-fifa-indonesia-naik-dua-pe...</td>\n",
       "      <td>Kabar gembira datang bagi   sepakbola   Indone...</td>\n",
       "      <td>Merdeka.com - Sebuah kabar gembira datang bagi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_indonesia_jakarta_orang_pemain</td>\n",
       "      <td>[indonesia, jakarta, orang, pemain, salah, neg...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Indonesia mencatat...</td>\n",
       "      <td>indonesia - jakarta - orang - pemain - salah -...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14261</th>\n",
       "      <td>Ada satu perangkat menarik lainnya yang tersaj...</td>\n",
       "      <td>1505421900-apple-tv-4k-usung-resolusi-super-be...</td>\n",
       "      <td>Ada satu perangkat menarik lainnya yang tersaj...</td>\n",
       "      <td>Ada satu perangkat menarik lainnya yang tersaj...</td>\n",
       "      <td>2</td>\n",
       "      <td>2_pebalap_startup_rossi_teknologi</td>\n",
       "      <td>[pebalap, startup, rossi, teknologi, berita, i...</td>\n",
       "      <td>[Jakarta, CNN Indonesia - - Pebalap Movistar Y...</td>\n",
       "      <td>pebalap - startup - rossi - teknologi - berita...</td>\n",
       "      <td>0.877063</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14262 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                document  \\\n",
       "0      Jakarta, CNN Indonesia - - Dokter Ryan Thamrin...   \n",
       "1      Selfie ialah salah satu tema terpanas di kalan...   \n",
       "2      Jakarta, CNN Indonesia - - Dinas Pariwisata Pr...   \n",
       "3      Merdeka.com - Indonesia Corruption Watch (ICW)...   \n",
       "4      Merdeka.com - Presiden Joko Widodo (Jokowi) me...   \n",
       "...                                                  ...   \n",
       "14257  Jakarta, CNN Indonesia - - Amerika Serikat dil...   \n",
       "14258  Bandung, CNN Indonesia - - Borneo FC berhasil ...   \n",
       "14259  JAKARTA (Pos Kota) – Komisi Pemberantasan Koru...   \n",
       "14260  Merdeka.com - Sebuah kabar gembira datang bagi...   \n",
       "14261  Ada satu perangkat menarik lainnya yang tersaj...   \n",
       "\n",
       "                                                      id  \\\n",
       "0      1501893029-lula-kamal-dokter-ryan-thamrin-saki...   \n",
       "1      1509072914-dua-smartphone-zenfone-baru-tawarka...   \n",
       "2      1510613677-songsong-visit-2020-bengkulu-perkua...   \n",
       "3      1502706803-icw-ada-kejanggalan-atas-tewasnya-s...   \n",
       "4      1503039338-pembagian-sepeda-usai-upacara-penur...   \n",
       "...                                                  ...   \n",
       "14257  1497645345-as-kirimkan-peluncur-rudal-ke-suria...   \n",
       "14258   1495406700-borneo-bersyukur-tahan-persib-di-gbla   \n",
       "14259  1513941815-mantan-dirjen-perhubungan-laut-sege...   \n",
       "14260  1496440800-rangking-fifa-indonesia-naik-dua-pe...   \n",
       "14261  1505421900-apple-tv-4k-usung-resolusi-super-be...   \n",
       "\n",
       "                                                 summary  \\\n",
       "0      Dokter Lula Kamal yang merupakan selebriti sek...   \n",
       "1      Asus memperkenalkan   ZenFone generasi keempat...   \n",
       "2      Dinas Pariwisata Provinsi Bengkulu kembali men...   \n",
       "3      Indonesia Corruption Watch (ICW) meminta Komis...   \n",
       "4      Jokowi memimpin upacara penurunan bendera. Usa...   \n",
       "...                                                  ...   \n",
       "14257  Amerika Serikat dilaporkan telah mengirimkan s...   \n",
       "14258  Borneo FC menahan imbang Persib Bandung pada l...   \n",
       "14259  Komisi Pemberantasan Korupsi (KPK) sudah melim...   \n",
       "14260  Kabar gembira datang bagi   sepakbola   Indone...   \n",
       "14261  Ada satu perangkat menarik lainnya yang tersaj...   \n",
       "\n",
       "                                                Document  Topic  \\\n",
       "0      Jakarta, CNN Indonesia - - Dokter Ryan Thamrin...     -1   \n",
       "1      Selfie ialah salah satu tema terpanas di kalan...     -1   \n",
       "2      Jakarta, CNN Indonesia - - Dinas Pariwisata Pr...     -1   \n",
       "3      Merdeka.com - Indonesia Corruption Watch (ICW)...     -1   \n",
       "4      Merdeka.com - Presiden Joko Widodo (Jokowi) me...      1   \n",
       "...                                                  ...    ...   \n",
       "14257  Jakarta, CNN Indonesia - - Amerika Serikat dil...      4   \n",
       "14258  Bandung, CNN Indonesia - - Borneo FC berhasil ...     -1   \n",
       "14259  JAKARTA (Pos Kota) – Komisi Pemberantasan Koru...      1   \n",
       "14260  Merdeka.com - Sebuah kabar gembira datang bagi...     -1   \n",
       "14261  Ada satu perangkat menarik lainnya yang tersaj...      2   \n",
       "\n",
       "                                    Name  \\\n",
       "0      -1_indonesia_jakarta_orang_pemain   \n",
       "1      -1_indonesia_jakarta_orang_pemain   \n",
       "2      -1_indonesia_jakarta_orang_pemain   \n",
       "3      -1_indonesia_jakarta_orang_pemain   \n",
       "4             1_jakarta_kpk_partai_ketua   \n",
       "...                                  ...   \n",
       "14257     4_trump_negara_presiden_israel   \n",
       "14258  -1_indonesia_jakarta_orang_pemain   \n",
       "14259         1_jakarta_kpk_partai_ketua   \n",
       "14260  -1_indonesia_jakarta_orang_pemain   \n",
       "14261  2_pebalap_startup_rossi_teknologi   \n",
       "\n",
       "                                          Representation  \\\n",
       "0      [indonesia, jakarta, orang, pemain, salah, neg...   \n",
       "1      [indonesia, jakarta, orang, pemain, salah, neg...   \n",
       "2      [indonesia, jakarta, orang, pemain, salah, neg...   \n",
       "3      [indonesia, jakarta, orang, pemain, salah, neg...   \n",
       "4      [jakarta, kpk, partai, ketua, indonesia, jalan...   \n",
       "...                                                  ...   \n",
       "14257  [trump, negara, presiden, israel, orang, ameri...   \n",
       "14258  [indonesia, jakarta, orang, pemain, salah, neg...   \n",
       "14259  [jakarta, kpk, partai, ketua, indonesia, jalan...   \n",
       "14260  [indonesia, jakarta, orang, pemain, salah, neg...   \n",
       "14261  [pebalap, startup, rossi, teknologi, berita, i...   \n",
       "\n",
       "                                     Representative_Docs  \\\n",
       "0      [Jakarta, CNN Indonesia - - Indonesia mencatat...   \n",
       "1      [Jakarta, CNN Indonesia - - Indonesia mencatat...   \n",
       "2      [Jakarta, CNN Indonesia - - Indonesia mencatat...   \n",
       "3      [Jakarta, CNN Indonesia - - Indonesia mencatat...   \n",
       "4      [Jakarta, CNN Indonesia - - Komisi Pemberantas...   \n",
       "...                                                  ...   \n",
       "14257  [Jakarta, CNN Indonesia - - Presiden Amerika S...   \n",
       "14258  [Jakarta, CNN Indonesia - - Indonesia mencatat...   \n",
       "14259  [Jakarta, CNN Indonesia - - Komisi Pemberantas...   \n",
       "14260  [Jakarta, CNN Indonesia - - Indonesia mencatat...   \n",
       "14261  [Jakarta, CNN Indonesia - - Pebalap Movistar Y...   \n",
       "\n",
       "                                             Top_n_words  Probability  \\\n",
       "0      indonesia - jakarta - orang - pemain - salah -...     0.000000   \n",
       "1      indonesia - jakarta - orang - pemain - salah -...     0.000000   \n",
       "2      indonesia - jakarta - orang - pemain - salah -...     0.000000   \n",
       "3      indonesia - jakarta - orang - pemain - salah -...     0.000000   \n",
       "4      jakarta - kpk - partai - ketua - indonesia - j...     0.918330   \n",
       "...                                                  ...          ...   \n",
       "14257  trump - negara - presiden - israel - orang - a...     0.450864   \n",
       "14258  indonesia - jakarta - orang - pemain - salah -...     0.000000   \n",
       "14259  jakarta - kpk - partai - ketua - indonesia - j...     1.000000   \n",
       "14260  indonesia - jakarta - orang - pemain - salah -...     0.000000   \n",
       "14261  pebalap - startup - rossi - teknologi - berita...     0.877063   \n",
       "\n",
       "       Representative_document  \n",
       "0                        False  \n",
       "1                        False  \n",
       "2                        False  \n",
       "3                        False  \n",
       "4                        False  \n",
       "...                        ...  \n",
       "14257                    False  \n",
       "14258                    False  \n",
       "14259                    False  \n",
       "14260                    False  \n",
       "14261                    False  \n",
       "\n",
       "[14262 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_document_info = topic_model.get_document_info(indosum.ds[\"train\"][\"document\"], indosum.to_pd(\"train\"))\n",
    "\n",
    "topic_document_info.to_csv(f\"./results/00-bertopic-indobart/topic_document_info.csv\")\n",
    "\n",
    "topic_document_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd41b882d0e473ab7ed9a1a1c65b18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/14262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'id', 'summary'],\n",
       "        num_rows: 14262\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'id', 'summary'],\n",
       "        num_rows: 3762\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'id', 'summary'],\n",
       "        num_rows: 750\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_topic(example, idx):\n",
    "    # if already have <tag>, return the example\n",
    "    if \"<tag>\" in example[\"document\"]:\n",
    "        return example\n",
    "\n",
    "    curr_topic = \" \".join(topic_document_info[\"Representation\"].values[idx])\n",
    "    example[\"document\"] = f\"<tag> {curr_topic} <tag> {example['document']}\"\n",
    "    \n",
    "    return example\n",
    "\n",
    "new_ds = indosum.ds\n",
    "new_ds[\"train\"] = new_ds[\"train\"].map(add_topic, with_indices=True, num_proc=os.cpu_count())\n",
    "\n",
    "indosum.update(new_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"document\": [\n",
      "        \"<tag> indonesia jakarta orang pemain salah negara anak film tim memiliki <tag> Jakarta, CNN Indonesia - - Dokter Ryan Thamrin, yang terkenal lewat acara Dokter Oz Indonesia, meninggal dunia pada Jumat (4 / 8) dini hari. Dokter Lula Kamal yang merupakan selebriti sekaligus rekan kerja Ryan menyebut kawannya itu sudah sakit sejak setahun yang lalu. Lula menuturkan, sakit itu membuat Ryan mesti vakum dari semua kegiatannya, termasuk menjadi pembawa acara Dokter Oz Indonesia. Kondisi itu membuat Ryan harus kembali ke kampung halamannya di Pekanbaru, Riau untuk menjalani istirahat. \\\" Setahu saya dia orangnya sehat, tapi tahun lalu saya dengar dia sakit. (Karena) sakitnya, ia langsung pulang ke Pekanbaru, jadi kami yang mau jenguk juga susah. Barangkali mau istirahat, ya betul juga, kalau di Jakarta susah isirahatnya, \\\" kata Lula kepada CNNIndonesia.com, Jumat (4 / 8). Lula yang mengenal Ryan sejak sebelum aktif berkarier di televisi mengaku belum sempat membesuk Ryan lantaran lokasi yang jauh. Dia juga tak tahu penyakit apa yang diderita Ryan. \\\" Itu saya enggak tahu, belum sempat jenguk dan enggak selamanya bisa dijenguk juga. Enggak tahu berat sekali apa bagaimana, \\\" tutur Ryan. Walau sudah setahun menderita sakit, Lula tak mengetahui apa penyebab pasti kematian Dr Oz Indonesia itu. Meski demikian, ia mendengar beberapa kabar yang menyebut bahwa penyebab Ryan meninggal adalah karena jatuh di kamar mandi. \\u201c Saya tidak tahu, barangkali penyakit yang dulu sama yang sekarang berbeda, atau penyebab kematiannya beda dari penyakit sebelumnya. Kita kan enggak bisa mengambil kesimpulan, \\\" kata Lula. Ryan Thamrin terkenal sebagai dokter yang rutin membagikan tips dan informasi kesehatan lewat tayangan Dokter Oz Indonesia. Ryan menempuh Pendidikan Dokter pada tahun 2002 di Fakultas Kedokteran Universitas Gadjah Mada. Dia kemudian melanjutkan pendidikan Klinis Kesehatan Reproduksi dan Penyakit Menular Seksual di Mahachulalongkornrajavidyalaya University, Bangkok, Thailand pada 2004.\",\n",
      "        \"<tag> indonesia jakarta orang pemain salah negara anak film tim memiliki <tag> Selfie ialah salah satu tema terpanas di kalangan produsen smartphone, bahkan menjadi senjata andalan beberapa brand terkenal. Anda mungkin berpikir bahwa saat ini, pasar handset spesialis selfie sudah sangat sesak. Tapi Asus masih melihat adanya peluang besar menanti di sana. Dari data mereka, sebanyak 71 persen orang Indonesia setidaknya mengambil selfie atau wefie setiap minggu. Setelah mulai menyelami ranah swafoto dua tahun silam lewat ZanFone Selfie, sang produsen hardware asal Taiwan itu akhirnya membawa sepasang pewarisnya ke tanah air. Handset - handset ini merupakan anggota keluarga ZenFone generasi keempat dan keduanya sama-sama dibekali setup kamera ganda di depan. Mereka adalah Asus ZenFone 4 Selfie Pro ZD552KL dan ZenFone 4 Selfie ZD553KL. CEO Asus Jerry Shen menjelaskan bahwa sudah waktunya bagi Asus untuk memberikan penawaran baru buat penggemar self - portrait demi menunjukkan keseriusan mereka di segmen itu. Walaupun \\u00a0 telah tersedia banyak pilihan, \\u00a0 Asus berpendapat bahwa konsumen di Indonesia membutuhkan solusi yang \\u2018 lebih profesional\\u2019. Dua ZenFone Selfie anyar ini kabarnya diracik sedemikian rupa sebagai jawaban atas kekurangan yang ada di perangkat - perangkat kompetitor, khususnya pada aspek jangkauan lensa dan performa di kondisi low-light. ZenFone 4 Selfie Pro \\u00a0 merupakan produk swafoto pamungkas Asus. Tubuh berbahan aluminiumnya dibuat melalui teknik nano molding dan tiap lekukannya dibentuk secara presisi. Dipadu layar berlapis Corning Gorilla Glass 5 2.5D, saya akui penampilan handset ini sangat menawan, terutama \\u00a0 untuk varian berwarna merahnya. Sebagai jendela akses konten, smartphone \\u00a0  menghidangkan layar AMOLED 1080p berkepadatan 401 ppi seluas 5,5 - inci. Atraksi utama dari ZenFone 4 Selfie Pro tentu saja adalah kamera depannya. Di sana, Asus mencantumkan sistem DuoPixel 24Mp, berisi kombinasi sepasang sensor Sony Exmor RS IMX362 1,4 \\u00b5m 12 - megapixel dengan aperture f/1.8, ditambah sensor Omnivision 5670 1,12 \\u00b5m f/2.2 yang memiliki lensa wide-angle 120 derajat, sehingga kamera bisa merangkul objek dua kali lebih banyak \\u2013 memungkinkan Anda ber-selfie bersama kawan ataupun keluarga tanpa bantuan monopod. Selain itu, Asus melengkapi ZenFone 4 Selfie Pro dengan bundel perkakas khusus swafoto bernama SelfieMaster. Tool ini berisi fitur-fitur krusial semisal beautify (buat foto maupun video), serta kolase dan BeautyLive. Produsen juga tak lupa menyiapkan flash LED softlight \\u00a0 untuk membantu pengambilan foto di kondisi temaram. Kamera belakangnya sendiri mengandalkan sensor Sony Exmor IMX351 1 \\u00b5m 16 - megapixel berlensa 26 mm f/2.2. Ia dibantu sistem electronic image stabilization, phase detection autofocus, serta LED dual - tone flash. Di dalam, Asus mempersenjatai ZD552KL dengan chip Qualcomm Snapdragon 625 (ada prosesor octa-core Cortex - A53 2 GHz dan GPU Adreno 506), RAM sebesar 4 GB, ROM 64 GB, dan baterai 3.000 mAh. Smartphone berjalan di sistem operasi Android 7.1.1 Nougat plus interface ZenUI 4.0. ZD553KL ialah alternatif lebih terjangkau dari saudarinya di atas. Handset mengusung arahan desain serupa ZenFone 4 Selfie Pro, namun konstruksi tubuhnya terbuat dari plastik, dan layar IPS 5,5 - incinya menyajikan resolusi 720p. Tapi jangan cemas soal penampilannya, smartphone tetap memanfaatkan kaca 2.5D sehingga memberi kesan menyambung pada lekukan di sisi samping. Kapabilitas swafoto ZenFone 4 Selfie bersandar pada sensor Omnivision 20880 1 \\u00b5m 20 - megapixel f/2.0 dan sensor Omnivision 8856 1,12 \\u00b5m f/2.4 dengan lensa wide-angle 120 derajat. Sudut jangkauan jepretan dan sejumlah kelengkapannya tak berbeda dari Selfie 4 Pro. Anda kembali dihindangkan SelfieMaster, flash LED softlight, mode panorama, serta HDR. Ukuran megapixel kamera belakangnya setara ZenFone 4 Selfie Pro, namun jenis sensornya berbeda. Smartphone tersebut menggunakan Omnivision 16880 1 \\u00b5m 16Mp dengan aperture lensa f/2.2. Meski demikian, fitur-fitur penunjang fotografi seperti PDAF, EIS, dan flash LED juga tetap ada di sana. ZenFone 4 Selfie diotaki system-on-chip Qualcomm Snapdragon 430, berisi CPU octa-core Cortex - A53 1,4 GHz dan GPU Adreno 505. Handset menyimpan RAM 4 GB, memori internal 64 GB, lalu tenaganya dipasok oleh baterai 3.000 mAh non - removable di dalam. Satu keunikan yang membuat ZD553KL lebih \\u2018 unggul\\u2019 dari ZenFone 4 Selfie Pro adalah dukungan tiga slot kartu: dua untuk SIM, dan satu lagi buat microSD (storage dapat diekspansi \\u00a0 sampai \\u00a0 2 TB). Smartphone juga beroperasi di platform Android 7.1.1 Nougat dengan ZenUI 4.0. ZenFone 4 Selfie Pro ZD552KL dibanderol seharga Rp 5 juta, sedangkan ZenFone 4 Selfie ZD553KL dipatok di harga Rp 3,5 juta. Kedua perangkat sudah mulai dipasarkan mulai tanggal 25 November, dan sampai \\u00a0 tanggal 10 November nanti, paket penjualan turut dibundel bersama \\u2018 Gong Yoo Special Gift Box\\u2019 serta speaker Bluetooth khusus ZenFone 4 Selfie Pro \\u2013 selama persediaan masih ada. DailySocial.id adalah portal berita startup dan inovasi teknologi. Kamu bisa menjadi member komunitas startup dan inovasi DailySocial.id, mengunduh laporan riset dan statistik seputar teknologi secara cuma-cuma, dan mengikuti berita startup Indonesia dan gadget terbaru.\",\n",
      "        \"<tag> indonesia jakarta orang pemain salah negara anak film tim memiliki <tag> Jakarta, CNN Indonesia - - Dinas Pariwisata Provinsi Bengkulu kembali menggelar kegiatan Bimbingan Teknis (Bimtek) SDM Kepariwisataan dalam menyongson \\\" Visit 2020 Wonderful Bengkulu \\\". Kegiatan yang berlangsung pada 8 hingga 10 November kemarin tersebut sebagai bagian dari upaya Pemerintah Provinsi Bengkulu dalam Hadir sebagai pemateri kegiatan pada 8 - 10 November itu adalah Plt. Asdep Strategi Pemasaran Pariwisata Nusantara, Deputi Bidang Pengembangan Pemasaran Pariwisata Nusantara Hariyanto serta perwakilan dari Deputi Bidang Pengembangan Kelembagaan Kementerian Pariwisata, Faizal. Kepala Dinas Pariwisata Provinsi Bengkulu Yudi Satria mengatakan, kegiatan Bimtek diikuti 250 peserta yang terdiri dari aparatur Pemerintah Provinsi, ASN Kabupaten / Kota, Kelompok Sadar Wisata serta pihak terkait sektor pariwisata di Bengkulu. \\\" Kegiatan ini dimaksudkan untuk memberikan pembekalan kepada peserta di bidang kepariwisataan, \\\" ujar Yudi Satria. Ia mengatakan, Pemprov telah menetapkan pariwisata sebagai salah satu sektor yang akan dikembangkan dan akan menjadi sektor unggulan dalam meningkatkan pertumbuhan ekonomi daerah serta masyarakat. Hal itu, jelas Yudi, tidak lepas dari potensi pariwisata di Bengkulu yang besar memiliki kekayaan alam yang indah serta budaya yang tinggi. \\\" Karena itu pula Pemprov telah menetapkan program' Visit 2020 Wonderful Bengkulu \\\" yang akan menjadi tujuan besar pariwisata Bengkulu. Salah satu poin utamanya adalah upaya menghasilkan SDM pariwisata yang andal yang akan diwujudkan melalui Bimtek ini, \\\" ujar Yudi. Selain itu, dalam menunjang proses' Visit 2020 Wonderful Bengkulu', Pemprov juga telah menyiapkan 52 acara yang akan digelar dalam satu tahun ke depan yang bertujuan mengangkat potensi lokal ke kelas dunia. \\\" Salah satu yang dirancang secara besar adalah Sail Bengkulu yang akan menjual keindahan alam laut Bengkulu yang berhadapan langsung dengan Samudera Hindia, \\\" kata dia. Ajang lainnya tentunya Festival Tabot Muharam yang selalu menyedot minat ribuan wisatawan setiap tahun serta Festival Bumi Rafflesia. \\\" Semua kegiatan ini harus disinkronkan, penguatan SDM dan bagaimana promosi pemasarannya agar semua acara ini layak jual untuk wisatawan, \\\" ujarnya. Sementara Hariyanto dalam kesempatan itu menyampaikan materi tentang pengembangan SDM sektor pariwisata dan pengemasan serta pemasaran satu acara. Dalam paparanya ia menjelaskan, bahwa Bimtek penting untuk meningkatkan kompetensi SDM kepariwisataan sehingga mampu berperan dalam peningkatan pembangunan kepariwisataan. Selain itu ia menegaskan bahwa dalam pengembangan pariwisata, promosi juga hal yang harus diperhatikan. Misalnya penekanan pada mekanisme promosi pariwisata secara digital atau daring, penyelenggaraan acara juga harus terkurasi dengan baik sehingga memiliki daya tarik yang kuat. \\\" Bagaimana juga meningkatkan efektivitas partisipasi Dinas Pariwisata pada penyelenggaraan acara dan bagaimana cara memasarkan dan mempromosikan agar bisa dikenal dan menjadi daya tarik wisatawan, \\u201d terang Hariyanto. Deputi Pengembangan Pemasaran Pariwisata Nusantara, Esthy Reko Astuti mengatakan, Bimtek kali ini juga bertujuan memberi perspektif dan arah yang sama tentang program promosi Pariwisata di Bengkulu. \\\" Selain itu juga untuk memahami potensi destinasi - destinasi wisata di Bengkulu, \\\" ujar Esthy. Menteri Pariwisata Arief Yahya mengapresiasi kegiatan Bimtek sebagai salah satu upaya dan komitmen dari Pemerintah Provinsi Bengkulu dalam mewujudkan pariwisata sebagai salah satu sektor utama. Ia pun berkomitmen akan mendung Penprov dalam mewujudkan \\\" Visit 2020 Wonderful Bengkulu \\\". \\\" Obyek wisata andalan Bengkulu, Benteng Marlborough, Rumah Bung Karno, Pantai Panjang yang memiliki pasir putih yang indah dan bersih. Semuanya world class, ditambah dengan puluhan atraksi didalamnya, tinggal kita akan dukung dan promosikan' Bengkulu Visit' sehingga lebih mendunia, \\\" kata Arief (syahb)\",\n",
      "        \"<tag> indonesia jakarta orang pemain salah negara anak film tim memiliki <tag> Merdeka.com - Indonesia Corruption Watch (ICW) meminta Komisi Pemberantas   Korupsi (KPK) ikut memantau perkembangan atas meninggalnya saksi kunci kasus mega korupsi e - KTP, Johannes Marliem. Peneliti ICW Divisi Hukum dan Monitoring Peradila, Aradila Caesar mengatakan momentum meninggalnya saksi kunci tersebut menimbulkan kejanggalan dan tanda tanya besar. \\\" Orang meninggal kita kan tidak bisa prediksi itu bukan kuasa kita. Tapi kalau kita melihat momentum kan ada suatu kejanggalan. Kenapa momentum meninggalnya, saat kasus e - ktp sedang ditangani oleh KPK, \\\" katanya seusai konferensi pers di Kantor Sekeretariatan ICW,   Jakarta, Minggu(13 / 8). Pihak ICW meminta KPK turut menyelidiki kematian saksi kunci ini dan menjelaskan kepada masyarakat apakah ada keterkaitan dengan permasalahan korupsi e - KTP atau hal-hal lain dibalik kematian Johannes. \\\" Kita minta KPK dan juga bekerja sama dengan pihak otoritas untuk menyelidiki kematian dari saksi kunci tersebut dengan serius. Artinya nanti KPK harus bisa menjelaskan kepada publik kenapa kematiannya, \\\" pintanya. ICW berharap dengan kematian saksi kunci, tidak membuat efek negatif untuk permasalahan kasus e - KTP ini. \\\" Jangan sampai kematiannya berdampak negatif dalam konteks membongkar kasus e - ktp tersebut, \\\" pungkasnya. [ded]\",\n",
      "        \"<tag> jakarta kpk partai ketua indonesia jalan tersangka gubernur orang korupsi <tag> Merdeka.com - Presiden Joko Widodo (Jokowi) memimpin upacara penurunan bendera di Halaman Istana Merdeka,   Jakarta. Usai prosesi penurunan bendera dilakukan, Jokowi kembali bagi-bagi sepeda kepada tamu undangan yang mengenakan pakaian adat terbaik. Berbeda dengan saat upacara pengibaran bendera, bagi-bagi sepeda kali ini diumumkan oleh Wakil Presiden Jusuf Kalla (JK). Hal berbeda juga terjadi bagi mereka yang menerima. Apabila sepeda diberikan ke pejabat negara mau pun keluarga, kali ini sepeda diberikan kepada masyarakat biasa. \\\" Seperti tadi pagi, sore ini juga panitia membentuk tim penilai untuk menilai siapa yang berbusana tradisional adat - adat daerah yang paling baik sore ini, \\\" kata JK. Kelima penerima sepeda di antaranya, Frans Maksim yang merupakan Kepala Suku Arfak, Papua, Ratna Dewi Budiono yang mengenakan pakaian adat Dayak, Yusak Rumambi yang mengenakan pakaian adat Sulawesi Utara, Teuku Johan Marzuki yang mengenakan pakaian adat Aceh. Terakhir, ada Sumahartarti yang mengenakan pakaian adat asal Bengkulu. \\\" Silakan semua datang ke panggung. Mendapat sepeda dari Bapak Presiden bisa langsung dipakai keliling - keliling nanti, \\\" ujarnya. Pada Upacara Pengibaran Bendera, lima orang menggunakan pakaian adat terbaik, yakni Menteri Hukum dan Hak Asasi Manusia (Menkum HAM) Yasonna Hamonangan Laoly dengan pakaian adat Nias, Ketua DPD RI Oesman Sapta Odang yang menggunakan pakaian adat Minang, dan Asisten Ajudan Presiden Syarif Muhammad Fidriansyah dengan pakaian adat Dayak, Kalimantan Barat. Dua orang lainnya adalah istri Kapolri Jenderal Pol Tito Karnavian, Tri Suswati yang mengenakan pakaian adat Papua, dan istri Wakil Ketua MPR Mahyudin, Agati Suli menggunakan baju adat Dayak. [bal]\"\n",
      "    ],\n",
      "    \"id\": [\n",
      "        \"1501893029-lula-kamal-dokter-ryan-thamrin-sakit-sejak-setahun\",\n",
      "        \"1509072914-dua-smartphone-zenfone-baru-tawarkan-solusi-bersel\",\n",
      "        \"1510613677-songsong-visit-2020-bengkulu-perkuat-sdm-pariwisat\",\n",
      "        \"1502706803-icw-ada-kejanggalan-atas-tewasnya-saksi-kunci-e-kt\",\n",
      "        \"1503039338-pembagian-sepeda-usai-upacara-penurunan-bendera\"\n",
      "    ],\n",
      "    \"summary\": [\n",
      "        \"Dokter Lula Kamal yang merupakan selebriti sekaligus rekan kerja Ryan Thamrin menyebut kawannya itu sudah sakit sejak setahun yang lalu. Lula menuturkan, sakit itu membuat Ryan mesti vakum dari semua kegiatannya, termasuk menjadi pembawa acara Dokter Oz Indonesia. Kondisi itu membuat Ryan harus kembali ke kampung halamannya di Pekanbaru, Riau untuk menjalani istirahat.\",\n",
      "        \"Asus memperkenalkan \\u00a0 ZenFone generasi keempat dan keduanya sama-sama dibekali setup kamera ganda di depan. Mereka adalah Asus ZenFone 4 Selfie Pro ZD552KL dan ZenFone 4 Selfie ZD553KL. Dua ZenFone Selfie anyar ini kabarnya diracik sedemikian rupa sebagai jawaban atas kekurangan yang ada di perangkat - perangkat kompetitor, khususnya pada aspek jangkauan lensa dan performa di kondisi low-light.\",\n",
      "        \"Dinas Pariwisata Provinsi Bengkulu kembali menggelar kegiatan Bimbingan Teknis (Bimtek) SDM Kepariwisataan dalam menyongson \\\" Visit 2020 Wonderful Bengkulu \\\" pada 8 - 10 November 2017 yang lalu. Kegiatan yang berlangsung pada 8 hingga 10 November kemarin tersebut sebagai bagian dari upaya Pemerintah Provinsi Bengkulu dalam memperkuat SDM Pariwisata untuk menyongsong \\\" Visit 2020 Wonderful Bengkulu \\\".\",\n",
      "        \"Indonesia Corruption Watch (ICW) meminta Komisi Pemberantas Korupsi \\u00a0 (KPK) ikut memantau perkembangan atas meninggalnya saksi kunci kasus mega \\u00a0 korupsi \\u00a0 e - KTP, Johannes Marliem dan menjelaskan kepada masyarakat apakah ada keterkaitan dengan permasalahan korupsi e - KTP atau hal-hal lain dibalik kematian Johannes. Peneliti ICW Divisi Hukum dan Monitoring Peradila, Aradila Caesar mengatakan momentum meninggalnya saksi kunci tersebut menimbulkan kejanggalan dan tanda tanya besar.\",\n",
      "        \"Jokowi memimpin upacara penurunan bendera. Usai prosesi tersebut, Jokowi bagi-bagi sepeda kepada tamu undangan yang mengenakan pakaian adat terbaik. Berbeda dengan saat upacara pengibaran bendera, bagi-bagi sepeda kali ini diumumkan oleh Wakil Presiden Jusuf Kalla (JK). Hal berbeda juga terjadi bagi mereka yang menerima. Apabila sepeda diberikan ke pejabat negara mau pun keluarga, kali ini sepeda diberikan kepada masyarakat biasa.\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(indosum.ds[\"train\"][:5], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "tokenizer.add_special_tokens({\"additional_special_tokens\": [\"<tag>\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBartForConditionalGeneration(\n",
       "  (model): MBartModel(\n",
       "    (shared): MBartScaledWordEmbedding(40004, 768, padding_idx=1)\n",
       "    (encoder): MBartEncoder(\n",
       "      (embed_tokens): MBartScaledWordEmbedding(40004, 768, padding_idx=1)\n",
       "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MBartEncoderLayer(\n",
       "          (self_attn): MBartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): MBartDecoder(\n",
       "      (embed_tokens): MBartScaledWordEmbedding(40004, 768, padding_idx=1)\n",
       "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MBartDecoderLayer(\n",
       "          (self_attn): MBartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=40004, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IndoNLGTokenizer(name_or_path='indobenchmark/indobart-v2', vocab_size=40004, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>', 'additional_special_tokens': ['<tag>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t39942: AddedToken(\"<tag>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t40003: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup evaluation\n",
    "metric = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a5805f86af4c4fb7061b7b54b69780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73e1466bb6d43c4a47d74079b8aa545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3762 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b134eb61bf0459b966be98cc1d1e55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/750 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare and tokenize dataset\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(examples[\"document\"], max_length=768, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"summary\"], max_length=128, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # decode preds and labels\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    decoded_preds = [\n",
    "        \"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds\n",
    "    ]\n",
    "    decoded_labels = [\n",
    "        \"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels\n",
    "    ]\n",
    "\n",
    "    result = metric.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    return result\n",
    "\n",
    "tokenized_ds = indosum.ds.map(preprocess_function, batched=True)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "def train_model(output_dir, per_device_batch_size, learning_rate, num_train_epochs, generation_max_length):\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir + \"/checkpoint\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=per_device_batch_size,\n",
    "        per_device_eval_batch_size=per_device_batch_size,\n",
    "        weight_decay=0.01,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        fp16=True,\n",
    "        predict_with_generate=True,\n",
    "        generation_max_length=generation_max_length,\n",
    "        log_level=\"info\",\n",
    "        logging_first_step=True,\n",
    "        logging_dir=output_dir + \"/logs\",\n",
    "        resume_from_checkpoint=True,\n",
    "        save_total_limit=1,\n",
    "    )\n",
    "\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_ds[\"train\"],\n",
    "        eval_dataset=tokenized_ds[\"validation\"],\n",
    "        processing_class=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    return trainer\n",
    "    \n",
    "def evaluate_model(trainer):\n",
    "    eval_results = trainer.evaluate(eval_dataset=tokenized_ds[\"test\"])\n",
    "    return eval_results\n",
    "\n",
    "\n",
    "def train_and_evaluate(output_dir, per_device_batch_size, learning_rate, num_train_epochs, generation_max_length):\n",
    "    trainer = train_model(output_dir, per_device_batch_size, learning_rate, num_train_epochs, generation_max_length)\n",
    "    eval_results = evaluate_model(trainer)\n",
    "    \n",
    "    return trainer, eval_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training & Evaluation\n",
    "\n",
    "Try multiple generation max length with the rest parameters fixed.\n",
    "Observes the best score and the corresponding generation max length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using auto half precision backend\n",
      "The following columns in the training set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 14,262\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5,349\n",
      "  Number of trainable parameters = 131,543,040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5349' max='5349' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5349/5349 23:22, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.546700</td>\n",
       "      <td>0.529217</td>\n",
       "      <td>0.654519</td>\n",
       "      <td>0.580659</td>\n",
       "      <td>0.622402</td>\n",
       "      <td>0.645601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.417400</td>\n",
       "      <td>0.519327</td>\n",
       "      <td>0.649801</td>\n",
       "      <td>0.576529</td>\n",
       "      <td>0.617606</td>\n",
       "      <td>0.641114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.328700</td>\n",
       "      <td>0.523548</td>\n",
       "      <td>0.643397</td>\n",
       "      <td>0.568776</td>\n",
       "      <td>0.610196</td>\n",
       "      <td>0.634588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1\n",
      "}\n",
      "\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/01/checkpoint/checkpoint-1783\n",
      "Configuration saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-1783/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-1783/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-1783/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-1783/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-1783/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/01/checkpoint/checkpoint-3566\n",
      "Configuration saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-3566/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-3566/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-3566/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-3566/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-3566/special_tokens_map.json\n",
      "Deleting older checkpoint [results/00-bertopic-indobart/01/checkpoint/checkpoint-1783] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/01/checkpoint/checkpoint-5349\n",
      "Configuration saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-5349/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-5349/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-5349/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-5349/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-5349/special_tokens_map.json\n",
      "Deleting older checkpoint [results/00-bertopic-indobart/01/checkpoint/checkpoint-3566] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/01/checkpoint/checkpoint-5349\n",
      "Configuration saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-5349/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-5349/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-5349/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-5349/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/01/checkpoint/checkpoint-5349/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3762\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 12:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using auto half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results for experiment ===\n",
      "-- Params --\n",
      "{\n",
      "    \"output_dir\": \"./results/00-bertopic-indobart/01\",\n",
      "    \"per_device_batch_size\": 8,\n",
      "    \"learning_rate\": 3.75e-05,\n",
      "    \"num_train_epochs\": 3,\n",
      "    \"generation_max_length\": 60\n",
      "}\n",
      "-- Eval results --\n",
      "{\n",
      "    \"eval_loss\": 0.5529609322547913,\n",
      "    \"eval_rouge1\": 0.6364351208505599,\n",
      "    \"eval_rouge2\": 0.5605365068088425,\n",
      "    \"eval_rougeL\": 0.6020757657731941,\n",
      "    \"eval_rougeLsum\": 0.6271883521878868,\n",
      "    \"eval_runtime\": 793.0146,\n",
      "    \"eval_samples_per_second\": 4.744,\n",
      "    \"eval_steps_per_second\": 0.594,\n",
      "    \"epoch\": 3.0\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 14,262\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5,349\n",
      "  Number of trainable parameters = 131,543,040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5349' max='5349' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5349/5349 24:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.275300</td>\n",
       "      <td>0.576374</td>\n",
       "      <td>0.672340</td>\n",
       "      <td>0.593267</td>\n",
       "      <td>0.636784</td>\n",
       "      <td>0.663334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.217200</td>\n",
       "      <td>0.578689</td>\n",
       "      <td>0.663294</td>\n",
       "      <td>0.583620</td>\n",
       "      <td>0.626504</td>\n",
       "      <td>0.654402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.584841</td>\n",
       "      <td>0.665344</td>\n",
       "      <td>0.585009</td>\n",
       "      <td>0.628543</td>\n",
       "      <td>0.656722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/02/checkpoint/checkpoint-1783\n",
      "Configuration saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-1783/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-1783/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-1783/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-1783/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-1783/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/02/checkpoint/checkpoint-3566\n",
      "Configuration saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-3566/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-3566/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-3566/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-3566/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-3566/special_tokens_map.json\n",
      "Deleting older checkpoint [results/00-bertopic-indobart/02/checkpoint/checkpoint-1783] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/02/checkpoint/checkpoint-5349\n",
      "Configuration saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-5349/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-5349/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-5349/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-5349/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-5349/special_tokens_map.json\n",
      "Deleting older checkpoint [results/00-bertopic-indobart/02/checkpoint/checkpoint-3566] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/02/checkpoint/checkpoint-5349\n",
      "Configuration saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-5349/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-5349/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-5349/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-5349/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/02/checkpoint/checkpoint-5349/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3762\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 14:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using auto half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results for experiment ===\n",
      "-- Params --\n",
      "{\n",
      "    \"output_dir\": \"./results/00-bertopic-indobart/02\",\n",
      "    \"per_device_batch_size\": 8,\n",
      "    \"learning_rate\": 3.75e-05,\n",
      "    \"num_train_epochs\": 3,\n",
      "    \"generation_max_length\": 70\n",
      "}\n",
      "-- Eval results --\n",
      "{\n",
      "    \"eval_loss\": 0.6192710995674133,\n",
      "    \"eval_rouge1\": 0.6510743666734569,\n",
      "    \"eval_rouge2\": 0.5681992626386996,\n",
      "    \"eval_rougeL\": 0.6118210096565171,\n",
      "    \"eval_rougeLsum\": 0.6414583163780941,\n",
      "    \"eval_runtime\": 901.8765,\n",
      "    \"eval_samples_per_second\": 4.171,\n",
      "    \"eval_steps_per_second\": 0.522,\n",
      "    \"epoch\": 3.0\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 14,262\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5,349\n",
      "  Number of trainable parameters = 131,543,040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5349' max='5349' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5349/5349 26:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.109900</td>\n",
       "      <td>0.666665</td>\n",
       "      <td>0.670484</td>\n",
       "      <td>0.585737</td>\n",
       "      <td>0.629444</td>\n",
       "      <td>0.660598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.661128</td>\n",
       "      <td>0.656109</td>\n",
       "      <td>0.569178</td>\n",
       "      <td>0.613230</td>\n",
       "      <td>0.646373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.655045</td>\n",
       "      <td>0.665903</td>\n",
       "      <td>0.580359</td>\n",
       "      <td>0.624929</td>\n",
       "      <td>0.656474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/03/checkpoint/checkpoint-1783\n",
      "Configuration saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-1783/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-1783/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-1783/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-1783/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-1783/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/03/checkpoint/checkpoint-3566\n",
      "Configuration saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-3566/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-3566/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-3566/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-3566/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-3566/special_tokens_map.json\n",
      "Deleting older checkpoint [results/00-bertopic-indobart/03/checkpoint/checkpoint-1783] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/03/checkpoint/checkpoint-5349\n",
      "Configuration saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-5349/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-5349/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-5349/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-5349/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-5349/special_tokens_map.json\n",
      "Deleting older checkpoint [results/00-bertopic-indobart/03/checkpoint/checkpoint-3566] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/03/checkpoint/checkpoint-5349\n",
      "Configuration saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-5349/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-5349/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-5349/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-5349/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/03/checkpoint/checkpoint-5349/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3762\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 16:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using auto half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results for experiment ===\n",
      "-- Params --\n",
      "{\n",
      "    \"output_dir\": \"./results/00-bertopic-indobart/03\",\n",
      "    \"per_device_batch_size\": 8,\n",
      "    \"learning_rate\": 3.75e-05,\n",
      "    \"num_train_epochs\": 3,\n",
      "    \"generation_max_length\": 80\n",
      "}\n",
      "-- Eval results --\n",
      "{\n",
      "    \"eval_loss\": 0.6935704946517944,\n",
      "    \"eval_rouge1\": 0.6526937238002135,\n",
      "    \"eval_rouge2\": 0.5666987399749325,\n",
      "    \"eval_rougeL\": 0.610787988799163,\n",
      "    \"eval_rougeLsum\": 0.642665223757774,\n",
      "    \"eval_runtime\": 1021.7749,\n",
      "    \"eval_samples_per_second\": 3.682,\n",
      "    \"eval_steps_per_second\": 0.461,\n",
      "    \"epoch\": 3.0\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 14,262\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5,349\n",
      "  Number of trainable parameters = 131,543,040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5349' max='5349' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5349/5349 27:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>0.750961</td>\n",
       "      <td>0.642532</td>\n",
       "      <td>0.553309</td>\n",
       "      <td>0.596652</td>\n",
       "      <td>0.632901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.043200</td>\n",
       "      <td>0.737981</td>\n",
       "      <td>0.647371</td>\n",
       "      <td>0.559988</td>\n",
       "      <td>0.603214</td>\n",
       "      <td>0.638072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.063100</td>\n",
       "      <td>0.715888</td>\n",
       "      <td>0.643812</td>\n",
       "      <td>0.555343</td>\n",
       "      <td>0.598235</td>\n",
       "      <td>0.634594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/04/checkpoint/checkpoint-1783\n",
      "Configuration saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-1783/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-1783/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-1783/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-1783/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-1783/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/04/checkpoint/checkpoint-3566\n",
      "Configuration saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-3566/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-3566/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-3566/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-3566/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-3566/special_tokens_map.json\n",
      "Deleting older checkpoint [results/00-bertopic-indobart/04/checkpoint/checkpoint-1783] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/04/checkpoint/checkpoint-5349\n",
      "Configuration saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-5349/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-5349/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-5349/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-5349/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-5349/special_tokens_map.json\n",
      "Deleting older checkpoint [results/00-bertopic-indobart/04/checkpoint/checkpoint-3566] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/04/checkpoint/checkpoint-5349\n",
      "Configuration saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-5349/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-5349/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-5349/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-5349/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/04/checkpoint/checkpoint-5349/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3762\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 18:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using auto half precision backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results for experiment ===\n",
      "-- Params --\n",
      "{\n",
      "    \"output_dir\": \"./results/00-bertopic-indobart/04\",\n",
      "    \"per_device_batch_size\": 8,\n",
      "    \"learning_rate\": 3.75e-05,\n",
      "    \"num_train_epochs\": 3,\n",
      "    \"generation_max_length\": 90\n",
      "}\n",
      "-- Eval results --\n",
      "{\n",
      "    \"eval_loss\": 0.7565310597419739,\n",
      "    \"eval_rouge1\": 0.6366294830203212,\n",
      "    \"eval_rouge2\": 0.5474059345855151,\n",
      "    \"eval_rougeL\": 0.5913407357360366,\n",
      "    \"eval_rougeLsum\": 0.6267238925254527,\n",
      "    \"eval_runtime\": 1172.786,\n",
      "    \"eval_samples_per_second\": 3.208,\n",
      "    \"eval_steps_per_second\": 0.402,\n",
      "    \"epoch\": 3.0\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 14,262\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5,349\n",
      "  Number of trainable parameters = 131,543,040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5349' max='5349' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5349/5349 28:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>0.820262</td>\n",
       "      <td>0.639454</td>\n",
       "      <td>0.551907</td>\n",
       "      <td>0.592439</td>\n",
       "      <td>0.629958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.797390</td>\n",
       "      <td>0.640681</td>\n",
       "      <td>0.553928</td>\n",
       "      <td>0.597334</td>\n",
       "      <td>0.631642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.763383</td>\n",
       "      <td>0.628980</td>\n",
       "      <td>0.539906</td>\n",
       "      <td>0.582585</td>\n",
       "      <td>0.619641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/05/checkpoint/checkpoint-1783\n",
      "Configuration saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-1783/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-1783/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-1783/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-1783/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-1783/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/05/checkpoint/checkpoint-3566\n",
      "Configuration saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-3566/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-3566/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-3566/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-3566/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-3566/special_tokens_map.json\n",
      "Deleting older checkpoint [results/00-bertopic-indobart/05/checkpoint/checkpoint-1783] due to args.save_total_limit\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/05/checkpoint/checkpoint-5349\n",
      "Configuration saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-5349/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-5349/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-5349/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-5349/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-5349/special_tokens_map.json\n",
      "Deleting older checkpoint [results/00-bertopic-indobart/05/checkpoint/checkpoint-3566] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/00-bertopic-indobart/05/checkpoint/checkpoint-5349\n",
      "Configuration saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-5349/config.json\n",
      "Configuration saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-5349/generation_config.json\n",
      "Model weights saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-5349/model.safetensors\n",
      "tokenizer config file saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-5349/tokenizer_config.json\n",
      "Special tokens file saved in ./results/00-bertopic-indobart/05/checkpoint/checkpoint-5349/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MBartForConditionalGeneration.forward` and have been ignored: summary, document, id. If summary, document, id are not expected by `MBartForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3762\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='471' max='471' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [471/471 21:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Results for experiment ===\n",
      "-- Params --\n",
      "{\n",
      "    \"output_dir\": \"./results/00-bertopic-indobart/05\",\n",
      "    \"per_device_batch_size\": 8,\n",
      "    \"learning_rate\": 3.75e-05,\n",
      "    \"num_train_epochs\": 3,\n",
      "    \"generation_max_length\": 100\n",
      "}\n",
      "-- Eval results --\n",
      "{\n",
      "    \"eval_loss\": 0.809755802154541,\n",
      "    \"eval_rouge1\": 0.6115544682348182,\n",
      "    \"eval_rouge2\": 0.5186660587803549,\n",
      "    \"eval_rougeL\": 0.5618226831013233,\n",
      "    \"eval_rougeLsum\": 0.6011072870063748,\n",
      "    \"eval_runtime\": 1339.4461,\n",
      "    \"eval_samples_per_second\": 2.809,\n",
      "    \"eval_steps_per_second\": 0.352,\n",
      "    \"epoch\": 3.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "experiments = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    generation_max_length = 50 + i * 10\n",
    "    experiments.append({\n",
    "        \"output_dir\": f\"./results/00-bertopic-indobart/0{i}\",\n",
    "        \"per_device_batch_size\": 8,\n",
    "        \"learning_rate\": 3.75e-5,\n",
    "        \"num_train_epochs\": 3,\n",
    "        \"generation_max_length\": generation_max_length\n",
    "    })\n",
    "\n",
    "for exp in experiments:\n",
    "    os.makedirs(exp[\"output_dir\"], exist_ok=True)\n",
    "    \n",
    "    trainer, eval_results = train_and_evaluate(\n",
    "        exp[\"output_dir\"],\n",
    "        exp[\"per_device_batch_size\"],\n",
    "        exp[\"learning_rate\"],\n",
    "        exp[\"num_train_epochs\"],\n",
    "        exp[\"generation_max_length\"]\n",
    "    )\n",
    "    \n",
    "    # print params and the results\n",
    "    print(\"=== Results for experiment ===\")\n",
    "    print(\"-- Params --\") \n",
    "    print(json.dumps(exp, indent=4))\n",
    "    print(\"-- Eval results --\")\n",
    "    print(json.dumps(eval_results, indent=4))\n",
    "    \n",
    "    # save mapping between params and results\n",
    "    with open(exp[\"output_dir\"] + \"/params.json\", \"w\") as f:\n",
    "        json.dump(exp, f)\n",
    "    \n",
    "    with open(exp[\"output_dir\"] + \"/eval_results.json\", \"w\") as f:\n",
    "        json.dump(eval_results, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
