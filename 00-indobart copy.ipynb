{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siagian/workspace/thesis/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/siagian/workspace/thesis/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import MBartForConditionalGeneration\n",
    "from torch import optim\n",
    "\n",
    "from repo.indobenchmark.toolkit.tokenization_indonlg import IndoNLGTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check that MPS is available\n",
    "# if not torch.backends.mps.is_available():\n",
    "#     if not torch.backends.mps.is_built():\n",
    "#         print(\"MPS not available because the current PyTorch install was not \"\n",
    "#               \"built with MPS enabled.\")\n",
    "#     else:\n",
    "#         print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "#               \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "# else:\n",
    "#     print(\"all good\")\n",
    "#     device = torch.device('mps')\n",
    "#     os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"1\" # This is tracked as pytorch issue #98222\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>id</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jakarta, CNN Indonesia - - Dilansir AFP, seora...</td>\n",
       "      <td>1494135000-wanita-terberat-di-dunia-jalani-fis...</td>\n",
       "      <td>Eman Ahmed Abd El Aty memiliki berat badan men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Menteri Pertahanan Ryamizard Ryacudu menyambut...</td>\n",
       "      <td>1501222980-kemhan-ingin-beli-drone-dari-china-...</td>\n",
       "      <td>Menteri Pertahanan Ryamizard Ryacudu menyambut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jakarta, CNN Indonesia - - Meski sudah hampir ...</td>\n",
       "      <td>1475739008-film-mean-girls-akan-dibuat-musikal</td>\n",
       "      <td>Rumah produksi film yang dibintangi Lindsay Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Usai melaksanakan ibadah haji, Eggi Sudjana ak...</td>\n",
       "      <td>1505785500-eggi-sudjana-sumpah-demi-allah-saya...</td>\n",
       "      <td>Eggi Sudjana akhirnya mendatangi kantor Baresk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Banyak cara untuk memberikan pengajaran kepada...</td>\n",
       "      <td>1497394800-kartu-muslim-optimalkan-teknologi-ar</td>\n",
       "      <td>Game permainan Kartu Muslim. Menggunakan basis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  Jakarta, CNN Indonesia - - Dilansir AFP, seora...   \n",
       "1  Menteri Pertahanan Ryamizard Ryacudu menyambut...   \n",
       "2  Jakarta, CNN Indonesia - - Meski sudah hampir ...   \n",
       "3  Usai melaksanakan ibadah haji, Eggi Sudjana ak...   \n",
       "4  Banyak cara untuk memberikan pengajaran kepada...   \n",
       "\n",
       "                                                  id  \\\n",
       "0  1494135000-wanita-terberat-di-dunia-jalani-fis...   \n",
       "1  1501222980-kemhan-ingin-beli-drone-dari-china-...   \n",
       "2     1475739008-film-mean-girls-akan-dibuat-musikal   \n",
       "3  1505785500-eggi-sudjana-sumpah-demi-allah-saya...   \n",
       "4    1497394800-kartu-muslim-optimalkan-teknologi-ar   \n",
       "\n",
       "                                             summary  \n",
       "0  Eman Ahmed Abd El Aty memiliki berat badan men...  \n",
       "1  Menteri Pertahanan Ryamizard Ryacudu menyambut...  \n",
       "2  Rumah produksi film yang dibintangi Lindsay Lo...  \n",
       "3  Eggi Sudjana akhirnya mendatangi kantor Baresk...  \n",
       "4  Game permainan Kartu Muslim. Menggunakan basis...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('maryantocinn/indosum')\n",
    "\n",
    "dataset['test'].to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MBartForConditionalGeneration(\n",
       "  (model): MBartModel(\n",
       "    (shared): MBartScaledWordEmbedding(40004, 768, padding_idx=1)\n",
       "    (encoder): MBartEncoder(\n",
       "      (embed_tokens): MBartScaledWordEmbedding(40004, 768, padding_idx=1)\n",
       "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MBartEncoderLayer(\n",
       "          (self_attn): MBartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): MBartDecoder(\n",
       "      (embed_tokens): MBartScaledWordEmbedding(40004, 768, padding_idx=1)\n",
       "      (embed_positions): MBartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MBartDecoderLayer(\n",
       "          (self_attn): MBartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MBartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=40004, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart_model = MBartForConditionalGeneration.from_pretrained('indobenchmark/indobart-v2')\n",
    "tokenizer = IndoNLGTokenizer.from_pretrained('indobenchmark/indobart-v2')\n",
    "\n",
    "model = bart_model\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = 1e-4\n",
    "gamma = 0.9\n",
    "lower = True\n",
    "step_size = 1\n",
    "beam_size = 5\n",
    "max_norm = 10\n",
    "early_stop = 5\n",
    "\n",
    "max_seq_len = 512\n",
    "grad_accumulate = 1\n",
    "no_special_token = False\n",
    "swap_source_target = True\n",
    "model_type = 'indo-bart'\n",
    "valid_criterion = 'SacreBLEU'\n",
    "\n",
    "separator_id = 4\n",
    "speaker_1_id = 5\n",
    "speaker_2_id = 6\n",
    "\n",
    "train_batch_size = 8\n",
    "valid_batch_size = 8\n",
    "test_batch_size = 8\n",
    "\n",
    "source_lang = \"[indonesian]\"\n",
    "target_lang = \"[indonesian]\"\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "src_lid = tokenizer.special_tokens_to_ids[source_lang]\n",
    "tgt_lid = tokenizer.special_tokens_to_ids[target_lang]\n",
    "\n",
    "model.config.decoder_start_token_id = tgt_lid\n",
    "\n",
    "# Make sure cuda is deterministic\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# create directory\n",
    "model_dir = './saved_models'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model to generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> aku pergi ke toko obat membeli<mask></s>[indonesian]\n",
      "<s> aku pergi ke toko obat membeli obat.[indonesian]\n"
     ]
    }
   ],
   "source": [
    "inputs = ['aku pergi ke toko obat membeli <mask>']\n",
    "bart_input = tokenizer.prepare_input_for_generation(inputs, return_tensors='pt', lang_token = '[indonesian]', decoder_lang_token='[indonesian]')\n",
    "\n",
    "# bart_input.to(device)\n",
    "bart_out = model(**bart_input)\n",
    "print(tokenizer.decode(bart_input['input_ids'][0]))\n",
    "print(tokenizer.decode(bart_out.logits.topk(1).indices[:,:].squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> kuring ka pasar senen meuli daging<mask></s>[sundanese]\n",
      "<s> kuring ka pasar senen meuli daging sapi,[sundanese]\n"
     ]
    }
   ],
   "source": [
    "inputs = ['kuring ka pasar senen meuli daging <mask>']\n",
    "bart_input = tokenizer.prepare_input_for_generation(inputs, return_tensors='pt', lang_token = '[sundanese]', decoder_lang_token='[sundanese]')\n",
    "\n",
    "# bart_input.to(device)\n",
    "bart_out = bart_model(**bart_input)\n",
    "print(tokenizer.decode(bart_input['input_ids'][0]))\n",
    "print(tokenizer.decode(bart_out.logits.topk(1).indices[:,:].squeeze()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
